# Day 1 - Intro To AI APIs

## Pre-lecture

- LMS Reading
- Sign up for API Key
- Fork and clone simple server repo
- Set up server
- Instructions in README

### AI Providers

- Remove <> from url
- must install zod@3
- only have them read it

## Exercise

- AI Chatbot

## Key takeaways

- Simple server with OpenAI SDK chat completions (mention of newer responses)
- structured output

# Day 2 - Local Setup & Prompt Chaining & Streaming

- NODE_ENV to `development`
- ollama list to see models
- open developer GUI for LM Studio, run server

## Lecture

- Demo downloading LLM and how to run
- Introduce streaming
- Add logic to handle it in backend
- Introduce logic to handle response in frontend

## Exercise

- Use ai-simple-server w/ local LLM & streaming
- Add streaming to Chatbot
- Prompt tutorial?

# Day 3 - Tool Calling

- instructions after Final response not clear in lecture article
- Exercise too open ended

## Pre-lecture

- Prompt chaining tutorial exercise
- Lecture article tutorial

## Lecture

- walk through tutorials
- give enough info they can add Travel Journal context

## Exercise

- add Posts written by user to context with Tool calling (open ended exercise to specific)

# Day 4 - Travel Journal Integration

## Lecture

- add ai-simple-serve to Microservices
- Add chatbot to SPA
- Update system instruction (refer to Gemini docs on how)
- Demo that initial basic integration
- Add context for signed in users with caching

- Structured output?
- Adding context?

## Exercise

- Add AI Chatbot to Travel Journal

# Day 5 (4) - MCP

- absolute path issue with Git
- query / command not working

# Day 6 (5) - Agentic AI
